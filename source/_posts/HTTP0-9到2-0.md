---
title: HTTP从0.9到2.0
date: 2021-05-09 21:17:28
tags: [HTTP/HTTPS]
categories: [笔记,计算机]
---
#### HTTP是什么？

超文本传输协议（Hypertext Transfer Protocol，HTTP），是<u>应用层</u>协议，基于请求-响应模式，无状态，运行在TCP之上（3.0版本改成了UDP），默认使用80端口（HTTPS是443端口）

#### HTTP 0.9

最传统的 request - response 模式

0.9版本极其简单，就只支持一个 `GET` 方法，没有什么格式

`GET /index.html`

#### HTTP 1.0

1.0版本拓展了报文结构相关一些东西

##### HTTP报文趋于完整

- 在请求中加入了HTTP版本号，比如：`GET /coolshell/index.html HTTP/1.0`，同时可以使用`POST`和`HEAD`了
- 不管是request还是response，都有头部（header）了
- 相应的也增加了HTTP Status Code 标识相关的状态码

到目前为止，HTTP报文就有了基本完整的结构

| 请求报文 | 响应报文 |
| -------- | -------- |
| 请求行   | 状态行   |
| 请求头   | 响应头   |
| 请求体   | 响应体   |

##### 提供了对不同类型资源的支持

- 增加了 `Content-Type`，`Content-Encoding`

从此，不仅可以传输文字，还可以传输图像、视频、二进制文件等各种各样格式的内容了

##### 增加了缓存机制

- 现在，HTTP能够使用Last-Modified/If-Modified-Since（协商缓存）和Expires（强缓存）策略来判断缓存了

##### 存在的缺陷

此时的浏览器和服务器之间的链接都是<u>短链接</u>，**每请求一个资源就要新建一个TCP链接，传输完后就关闭**。而我们往往需要多次请求，这样就需要反复建立/断开TCP链接。同时HTTP 1.0是**串行请求**，很容易造成队头堵塞问题

#### HTTP 1.1

##### 长链接和管线化

- 可以设置在头部设置 `Connection:Keep-Alive` 来让HTTP**重用TCP链接**。

  这就解决了1.0的问题，不必每次请求都要进行TCP链接，毕竟每一个TCP链接都要经过三次握手四次挥手，开销巨大。这就是所谓的“**HTTP 长链接**” 或是 “**请求响应式的HTTP 持久链接**”（HTTP Persistent connection），只要任意一端没有明确提出断开连接，则保持TCP连接状态（使用`Connection: close` 来断开）。

  HTTP 1.1中，服务器和客户端都是默认使用长链接。如果不想使用长链接的话就要在header里指明 `Connection: close`

- 支持 pipeline （管线化）网络传输，**不用等待响应即可直接发送下一个请求**（原本发送请求后需要等待并接收响应）。可以减少整体的响应时间。

根据以上两个新特性，HTTP 1.1可以在一次链接中处理多个请求，并且这些请求的过程可以重叠进行，但服务器端必须按照接收到客户端请求的**先后顺序**依次回送响应结果，以保证客户端能够区分出每次请求的响应内容
![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/20170516223641344.jpeg)

##### 节约带宽

- 加入了新的状态码 100（Continue）

  如果客户端想要发送数据量很大的请求时，先发送一个**只有请求头**的报文，看服务器是否接受。服务器允许则会返回状态码 100的响应报文（拒绝则是401），然后客户端就可以发送大的请求报文了

  客户端request的header中加入`Expect: 100-continue`字段

- 加入了新的状态码 206（Partial Content）

  1.0中，如果客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。

  1.1中，在请求头中加入range，允许只请求资源的某个部分，如果服务器能够正常响应的话，服务器会返回 206， 如果不能处理这种Range的话，就会返回整个资源，响应状态码为 200。

  可以通过这个来实现分段下载，断点续传。

##### 新增缓存策略

- 强缓存增加 Cache-Control
- 协商缓存增加 Etag / If-None-Match

##### 增加了更多的头部字段来扩充功能

- 协议头中增加了 `Language`, `Encoding`, `Type` 等等头，让客户端可以跟服务器端进行更多的协商
- 正式加入了一个很重要的请求头字段： `HOST` 。这样的话，服务器就知道你要请求哪个网站了。因为<u>可以有多个域名解析到同一个IP上</u>，要**区分用户是请求的哪个域名**，就需要在HTTP的协议中加入域名的信息，而不是被DNS转换过的IP信息

##### 增加了新的请求方法

- 正式加入了 `OPTIONS` 方法，其主要用于 CORS – Cross Origin Resource Sharing 应用

###### 常用请求方法

- GET 请求获取Request-URI所标识的资源
- POST 在Request-URI所标识的资源后附加新的数据
- HEAD 请求获取由Request-URI所标识的资源的响应消息报头
- PUT 请求服务器存储一个资源，并用Request-URI作为其标识
- DELETE 请求服务器删除Request-URI所标识的资源
- TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断
- CONNECT 保留将来使用
- OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求

##### 存在的缺陷

虽然1.1能够复用TCP连接了，但是仍然是**串行**发送请求的。同一个TCP连接里面，所有的数据通信按次序进行。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。所以跟1.0一样，有"**队头堵塞**"现象（HOLB）

##### 优化方案

- 减少请求数量（比如把脚本和样式表合并、将图片嵌入CSS里）
- 同时多开持久链接

#### SPDY：HTTP 1.1 的增强版，HTTP 2.0 的预览版

Google提出来的这个方案（speedy），优化了请求延迟，解决了安全性问题。

在HTTP和TCP之间插入一个协议，只是优化了性能，没有对HTTP做很大的改动

![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/562880-20161126171020846-132545577.png)

##### 降低延迟

- 采取**多路复用**，多个请求stream共享一个TCP连接，避免了创建多个TCP带来的延迟
- 引入**请求优先级**，重要的请求优先响应，避免关键数据被阻塞
- 使用**头部压缩**，header很多时候都是重复多余的，使用压缩算法（HPACK）减小大小。
- 支持**服务端推送**，服务端主动推送文件给客户端，让它先缓存起来

##### 提升安全性

- 强制使用**HTTPS**协议，禁止明文传输

#### HTTP 2.0

虽然1.1加入了重用TCP这种操作，但是<u>请求仍然是**串行**发送</u>的，需要保证顺序。但是对于日益复杂的网页，资源类的东西越来越多，它们占据了所有HTTP请求中最多的传输数据量。如果能想办法<u>让这些请求**并行**发送</u>，就能提高网络吞吐和性能

此外，HTTP 1.1传输数据时，会进行内容编码，也就是<u>压缩报文内容</u>（常用gzip），它消耗客户端和服务器的CPU资源。

HTTP 2.0 在 SPDY的基础上发展而来，吸收它的许多优点和思想，大幅提高了HTTP的性能

##### 二进制分帧

所有传输信息都会被分割，并使用二进制格式编码。为了保证HTTP不受影响，那就需要在应用层（HTTP2.0）和传输层（TCP or UDP）之间增加一个二进制分帧层。在二进制分帧层上，HTTP2.0会将所有传输的信息分为更小的消息和帧，并采用二进制格式编码，其中HTTP1.x的首部信息会被封装到Headers帧，而Request Body则封装到Data帧

![preview](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/view.png)

- 帧：2.0里数据通信的最小单位

  包含类型（Type），长度（Length），标记（Flags），流标识（Stream Identifier）和有效载荷（frame payload）

  流标识：标识该帧属于哪个流

  标记：标识该帧组装时在整个消息中应在的位置

- 消息：指的是HTTP一个完整的请求或响应，**消息由一个或多个帧组成**

- 流：连接中的一个虚拟信道，可以承载双向信息传输
  每个流都有一个唯一的整数ID。为了避免两端流ID冲突，客户端发起的流是奇数ID，服务器发起的流是偶数ID

##### 多路复用

**一个**HTTP 2.0 连接上可以有**多个并发**打开的流，每个数据流以消息的形式发送，而这些消息由一个或多个帧组成，这些帧可以乱序发送，然后在接收端根据每个帧首部的流标识符和标记重新组装

![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/20210413001134.png)

简单的说，就是将原本完整的一个消息，拆分成几个帧，然后这几个帧有自己的流标识，有自己的标记，所以可以和其它消息的帧混在一起发送，到达目的地后组装起来又成为完整的消息。

**HTTP性能的关键在于低延迟而不是高带宽！**大多数HTTP 连接的时间都很短，而且是突发性的，但TCP 只在长时间连接传输大块数据时效率才最高（慢启动策略）。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用TCP 连接，让高带宽也能真正的服务于HTTP的性能提升。

##### 头部压缩

HTTP 1.x的头带有大量信息，而且每次都要<u>重复发送</u>。HTTP 2.0使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。

**对于相同的头部，每次请求和响应不会多次发送**，因为<u>通信期间几乎不会改变通用键-值对</u>（用户代理、可接受的媒体类型，等等）所以只需要发送一次就够了。

事实上,如果请求中不包含首部（例如对同一资源的轮询请求），那么首部开销就是零字节，此时所有首部都自动使用之前请求发送的首部。

如果首部发生了变化，则只需将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表在 http 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新

###### 压缩原理

HTTP 2.0 使用HPACK算法专门处理头部字段

它使用一份索引表来定义常用的HTTP Header，把常用的 HTTP Header 存放在表里，请求的时候便只需要发送在表里的索引位置即可，用索引来代替实际的Header

例如 :method=GET 使用索引值 2 表示，:path=/index.html 使用索引值 5 表示

![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/20210413003646.webp)

索引表包括两个部分

- Static Table：一些常用的HTTP Header字段
- Dynamic Table：动态添加的HTTP Header

##### 请求优先级

把http消息分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的**优先值**：0 表示最高优先级；2的31次方-1 表示最低优先级

服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。**高优先级的流都应该优先发送，但又不是绝对的。绝对地遵守，这样可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付**。分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。

优先级从高到低：主要的HTML -> CSS文件 -> JS文件 -> 图片等其它资源

##### 服务端推送

在客户端请求之前发送数据，即**还没有收到浏览器的请求，服务器就把各种资源推送给浏览器**

浏览器没有请求的东西，我服务端可以先送给你放在你的本地缓存中。比如，客户端请求X，服务端知道X依赖于Y，虽然没有请求Y，但我把Y跟着X的请求一起返回客户端。这样在一次请求中，就得到了多个资源，省去了客户端重复请求的步骤。

![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/20210413115901.webp)

当服务端需要主动推送某个资源时，便会发送一个 Frame Type 为 `PUSH_PROMISE` 的 Frame，里面带了 PUSH 需要新建的 Stream ID。意思是告诉客户端：接下来我要用这个 ID 向你发送东西，客户端准备好接着。客户端解析 Frame 时，发现它是一个 `PUSH_PROMISE` 类型，便会准备接收服务端要推送的流。

服务端可以主动推送，客户端也有权利选择是否接收。如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 `RST_STREAM` 帧来拒收。主动推送也遵守同源策略，服务器不会随便推送第三方资源给客户端。

虽然看起来很美好，实际上还是有一些问题的。对于所要推送的资源文件，如果<u>浏览器已经有缓存</u>，推送就是浪费带宽。即使推送的文件版本更新，浏览器也会优先使用本地缓存。有一种解决办法是：只对第一次访问的用户使用服务器推送，根据 Cookie 判断是否为第一次访问

##### HTTP 2.0和SPDY的区别

- HTTP 2.0 **不强制**使用HTTPS，可以选择不使用SSL/TLS
- 对于头部压缩算法，SPDY 采用 **DEFLATE**，HTTP 2.0使用 **HPACK**

##### 性能瓶颈

现在所有的压力集中在底层一个TCP连接之上，比如TCP分组的**队首阻塞**问题，若干个HTTP的请求在复用一个TCP的连接，底层的TCP协议是不知道上层有多少个HTTP的请求的，所以，一旦单个TCP packet丢失，整个连接都会阻塞，此时所有的HTTP请求都必需等待这个丢了的包被重传回来。

###### 队首阻塞（Head-of-Line Blocking，HOL）

![img](https://cdn.jsdelivr.net/gh/kudryavka1013/note-pic@master/note/HOL_blocking.png)

左边的是四个输入队列，四个队列中的数据包要去的右边的output的对应数字的端口。此时，第一个队列和第三个队列都要写右边的第四个端口，然后，一个时刻只能处理一个包，所以，一个队列只能在那等另一个队列写完后。然后，其此时的3号或1号端口是空闲的，而队列中的要去1号和3号端口的数据，被第4号端口给block住了。这就是所谓的HOL blocking问题。

在HTTP/1.1中，pipeline中如果有一个请求block了，那么队列后请求也统统被block住了；HTTP 2.0 中，多个请求复用一个TCP连接，一旦发生丢包，同样会block住所有的HTTP请求

到这里为止，TCP已经到它的极限了，这不是通过优化就能解决的问题，这是TCP本身的局限性。那么，我们还有什么解法吗？答案是 HTTP 3.0 改用UDP，那是更复杂的东西了。

#### 参考

[HTTP1.0、HTTP1.1 和 HTTP2.0 的区别](https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A)

[HTTP的前世今生](https://coolshell.cn/articles/19840.html#HTTP_09_10)

[HTTP0.9、HTTP1.0、HTTP1.1、HTTP2、HTTP3的区别](https://blog.csdn.net/qq_35642036/article/details/82788314)

[HTTP2.0性能增强的核心：二进制分帧](http://www.linuxidc.com/Linux/2015-08/122287.htm)
